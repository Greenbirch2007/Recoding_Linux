

第7章 使用过滤器操作文本文件

过滤器通常标准输入设备接受输入,对其进行处理,然后将结果写入标准输出设备.管道用于在过滤器之间传送输入和输出,
形成一条数据管线

本章介绍wc,nl,cut,sort,uniq,tr,sed,awk

上一些命令存在重叠的效果

sort和uniq大致相同
sed和awk大致相同


7.1  计算文件中的单词数,行数和字符数

wc 行数,单词书数,字符数


-l提供行数
-w提供单词数
-m字符串数

组合使用更好

如果在wc命令的输出中不想包括空白行的数量,可使用sed删除文档中的所有空白行,然后将结果通过管道传递给wc -l 命令

7.2  对文件中的行编号
nl 文件名

如果仔细查看输出,会注意到没有对空白行编号.这是使用nl命令的默认行为,的呢沟通与使用-b t选项


7.3  选择分隔文件中的整列数据

cut 

即使我们不使用制表符分隔文件中的数据,也通常会使用其他的符号:例如,逗号,分号,冒号和句点.cut命令用于从与特定符号分隔的文件中选择指定的列,然后农户输出这些列

从制表符开始讨论,因为这是cut命令默认寻找的符号.
为提取数据的第一列和第三列,可以使用

cut -f 1,3  a.txt

如果要获取第一列到第三列的所有数据,可使用 -f 1-3,
如果要获取除第二列之外的所有列,则使用 -f 1,3-4

服务器的主机名
wu.images.granneman.com
顶级域名(com),二级域名(granneman),三级域名(images),但是不需要四级域名(wu)

echo wu.images.granneman.com | cut -d "." -f 2-4(类似与正则的用法)

如果要用其他分隔符,如逗号,应该如何处理?只需使用--output-delimiter选项,并告诉cut你想用的分隔符


在上面的示例中制表符充当分隔符,但是如果采用其他分隔符,情况会如何?使用-d选项指定分隔符
在linux计算机中,$HOMENAME是计算机主机名的环境变量, 用cut把计算机的实际名称和域名分开

echo $HOSTNAME | cut -d "-" -f 2

又如,分隔url

http://www.baidu.com/news/toady

可以采用分隔符是正斜杠(/)

echo http://www.baidu.com/news/toady | cut -d "/" -f 3


得到 www.baidu.com

7.4  排序文件的内容

sort  该命令的作用是对文件的内容进行排序. 按照字母排序

可以使用sed命令和ld选项删除第一行,然后将结果通过管道传递到sort命令
下面是数字1
sed 1d a.txt | sort

如果按照文本中的时间,应该如何处理?这是可以用-k选项为排序操作选择不同的列,在示例中是按第4个制表符选择的字段.
然而,sort命令默认使用空格作为分隔符,因此需要向该命令表明要查找的分隔符为制表符

sed 1d a.txt | sort -t "   " -k 2

在-t选项后面指定制表符的最简单方式是输入单引号,按ctrl+v组合键,最后输入另一个单引号

如果要按年份排序,但是采用倒序,应该如何处理?这是使用 -r选项
sed 1d a.txt | sort -t "   " -k 2 -r

7.5  按数字排序文件的内容

sort -n
sort  -h

事实上,sort将年份视为字符串

下面自我服务器的一天的数据.其中更清晰地显示了数字字符串的工作方式.
首先使用du命令,该命令报告文件系统或文件夹的磁盘使用情况.
du命令的-d l 选项指定该命令应该报告的层次深度;
-d 1 表示报告/var中下一层目录的大小(因此是以1为深度)
使用该命令获得/var的子目录的大小(以字节为单位),然后将结果通过管道传递到sort命令

cd /var
du -d 1 | sort    (是数字1)

请注意,字节是按字符串排序:首先是1s(以1开头的字符串),然后是2s,接下来是3s
但是,这些字节确实没有按数字方式排序!这次使用sort命令和-n选项

du -d 1 | sort -n

按照文件大小大小进行排序

du -d 1 -h | sort -n

按照文件大小倒叙
du -d 1 -h | sort -h



7.6  删除文件中重复的行

uniq  

history命令以编号形式列出输入到bash中的命令.第一列是编号列表,编号之后是命令,选项和文件的长列表,而在此只需要命令(如cd 或man)使用awk命令从history的输出中取出第二个空格分隔的列

history | awk "{print$ 2}"

使用uniq可以去除重复的命令

history | awk "{print$ 2}" | uniq

注意,uniq只会省略彼此相邻的重复行.在显示的清单中,为了解决这个问题,可以用sort先进行字母顺序命令列表,然后将排序的
结果通过管道传递到uniq

history | awk "{print $2}" | sort | uniq

查看命令运行的次数

history | awk "{print $2}" | sort | uniq -c

查看命令运行次数的排序

history | awk "{print $2}" | sort | uniq -c | sort -n


7.7 使用其他字符替换选择的字符

tr  该命令用于将一组字符转换(实际上,"替换"可能是更好的措辞)为另一组字符.例如,可使用tr从单词从小写换成大写

echo " H.PASDFAS  Loverase" | tr a-z A-Z

也可以采用字符类代表整组字符
[:alnum:] :字母数字(A-Z,a-z和0-9)
[:alpha:]  字母(A-Z和a-z)
[:blank:] 空白(空白和制表符)
[:digit:] 数字(0-9)
[:lower:] 小写字母(a-z)
[:punct:] 标点和符号(如你预期)
[:space:] 空格(空格,制表符,换行以及垂直空白)
[:upper:] 大写字母(A-Z)


小写转大写

echo " H.PASDFAS  Loverase" | tr [:lower:] [:upper:] 

大写转小写
echo " H.PASDFAS  Loverase" | tr [:upper:] [:lower:]

7.8  使用单个实例替换重复字符

tr -s 该选项用于将特定字符的每个重复缩减为单个实例.


tr -s [:blank:] < a.txt

可以看到,文件从每个句点后两个空格,变成了一个空格.
注意,[:blank:]只表示空格和制表符
[:space:]还额外表示换行(以及其他一些字符).如果该文件中有多个段落,[:space:]就会删除换行,这意味着所有段落
将拥挤在一起

7.9  删除匹配的煮饭吃

tr -d 该选项可删除字符.
一个脚本(函数)


web_ready (){
[ "$(1)" ] || return
extension=$(echo "$(1)" | awk -F . "{print $NF}")
mv "$(1)" $(echo "$(1)" |
iconv -f utf-8 -t ascii//translit |
tr -d '[:punct:]' |
tr [:upper:] [:lower:] |
sed "s/${extension}$./$extension/" |
tr '' '-')}

需要删除标点符号,将所有字母改为小写,以及使用连字符替换空格.(就是脚本里的函数做的做的工作)

函数的第一行[ "$(1)" ] || return 确保在web_ready命令之后提交参数(文件的名称),入股偶没有这样的参数,则函数退出


第二行extension=$(echo "$(1)" | awk -F . "{print $NF}")  创建一个名为extension的变量.分配给该变量的值在$(和)之间执行的命令替换的结果.
我们将第一个(唯一的)以参数会搜狗到web_ready命令,即文件的名称,有"${1}"表示(使用双引号是为了防止文件名中有空格)

接下来,将文件名通过管道传递到awk命令,借助-F选项,该命令了解到.符号是分隔付.'{print $NF}'告诉awk命令打印分隔文件中的最后一行,在此例中是文件的扩展名(此处为pdf,但是可以为任何扩展名,如html,markdown,jpg)

extension变量现在保存文件扩展名的值:pdf,很快就会用到这个值


第三行:首先使用mv命令将文件从其原始名称(再次由第一个参数("${1}")表示)重命名为可在网络发布的名称,即用命令替换获得5个管道符的结果.

首先,我们使用echo "${1}"声明文件的名称,然后立刻将结果通过管道传递到iconv -f utf-8 -t ascii//translit
该命令将文件和文本从一种编码格式(在此为-f utf-8)转换为另一种(此处为 -t ascii)

代码末尾的//translit告诉iconv,如果其目标编码之外的字符,它就可以自动替换为类似外观的字符

我们将文件名通过管道传递到tr -d '[:punct:]',该命令会删除名称中的所有标点符号,
下面将结果通过管道传递给tr [:upper:] [:lower:] ,该命令是使用小写字母替换大写字母

sed "s/${extension}$./$extension/"  修复口占的问题,通过管道传递到sed命令,并且最终利用extension变量:${extension}.我们告诉sed利用句点替换extension变量的值(pdf),然后添加这个值,最终得到.pdf

注意


${extension} 和$extension的区别?
它们没有区别,它们表示相同的食物,只不过${extension}更易于阅读,并且更容易被视为变量
很明显${extension}是变量,其代表pdf

一个例子

extension=pdf
echo "this pdf is ready for youpdf" | sed "s/${extension}/.$extension/"

sed找到第一个替换目标后会停止执行,因此我们在第一个pdf实例之前的据典出(this.pdf)结束,留下没有真正扩展名的文件名(youpdf).然而,正则表达式中的$始终表示字符串的结束,因此${extension}$中的第二个$匹配扩展名,因为扩展名始终在文件名的末尾.
从本质上来说,${extension}$告诉sed查找${extension}(pdf)的值,但是当该值出现在字符串的末尾(以$表示)时才会替换(因此youpdf会变成you.pdf)

tr '' '-',该命令使用tr命令将文件名中的每个空格改为连字符,最终得到我们寻求的文件名,


7.10  转变文件中的文本

sed 

sed是流编辑器(stream editor)的缩写,这表示它用于转变文件中或通过重定向提供的文本流.为充分利用sed,需要理解正则表达式(regex)

关于sed,可以使用该命令进行给你换.
假设有一个自动生成的文件,该文件以.markdown.txt结尾,而你希望扩展为.markdown,即么有.txt

touch asdfaw.py.txt
title="asdfaw.py.txt"
mv "$title"  "$(echo  "title" | sed 's/py.txt/py')" s表示字符串替换

s/wud/wood/g中的字母g,其代表"全局",添加g标志时,sed会替换每个输入行上的每个匹配单词或模式的实例.
更好的方法是使用sed命令和-i.这会实际地更改文件以反映sed命令执行的改动,因此你明显要确保sed将按照你要的方式进行更改

在sed命令中可使用并且将要使用正则表达式.比如要大量替换时

假设有一个包含bash shell脚本的文件,该文件充满注释,以#开头的行,需要删除这些行,单保留第一行

上面的需求要用到d命令和少量正则表达式


cat handoonv.sh

sed -i '1n; /^[[:blank:]]*#/d' handconv.sh

真正执行操作的命令部分是1n; /^[[:blank:]]*#/d
末尾出的d执行删除操作,
ln;的作用是告诉sed跳过第一行,继续往下执行,然后我们就进入了模式匹配过程
我们要删除以#开头的的其他行:例子中,我们的模式是/^#/(^表示行的开头).这会捕捉以#开头的所有行,
[[:blank:]]*表示匹配零次或多次空格.

7.11  打印文件中的特定字段

awk

awk命令用于在文件和输入中从查找相关模式,然后过滤项目并编写报告.
awk实际上是编程语言,它有变量,函数,数组,系统调用以及其他对象,而sed不是
在一台服务器上,邮件池文件有时显得有些庞大,因此要定期检查其大小并在必要时进行数据分流.
首先,简单使用wc命令查找mail文件有多少个字节

wc -c /home/lk/a.txt

但我只需要字节数,不需要文件的名称,使用awk,通过指定$1 仅输出实际带下,$1告诉该命令仅仅打印第一行

wc -c /home/lk/a.txt | awk '{print $1}'

显示具体大小
wc -c /home/lk/a.txt | awk '{print "doc is " $1/1024 "MB" }'

获取一些数据列,并且取出一些列做为小型报告显示,df -h可显示计算机文件系统的中的磁盘情况

但是只想输出若干列,就要用到awk重写输出

df -h | awk '{print $6 "has" $4 "of" $2 "left"}'

df -h | awk ' NR>1 {print $6 "has" $4 "of" $2 "left"}'

NR>1告诉awk跳过第一行(no row?).NR是awk命令中的特殊变量,其代表awk到目前位置在文件中查看的记录(行)数
awk每处理一行,该变量就递增1

7.12 

泰勒 编程定律

